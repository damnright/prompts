model = "gpt-5.2"
model_reasoning_effort = "low"
# Enable Streamable HTTP MCP servers (OAuth, bearer tokens, etc.)
experimental_use_rmcp_client = true
[mcp]
enable = true
timeout_ms = 60000

[mcp_servers.filesystem]
command = "npx"
args = ["-y", "@modelcontextprotocol/server-filesystem", "c:\\my"]

[mcp_servers.git]
command = "uvx"
args = ["mcp-server-git"]

[mcp_servers.fetch]
command = "uvx"
args = ["mcp-server-fetch"]

[mcp_servers.time]
command = "uvx"
args = ["mcp-server-time"]

[mcp_servers.sequential-thinking]
command = "npx"
args = ["-y", "@modelcontextprotocol/server-sequential-thinking"]

[mcp_servers.memory]
command = "npx"
args = ["-y", "@modelcontextprotocol/server-memory"]

[mcp_servers.memory.env]
MEMORY_FILE_PATH = "C:\\Users\\yy\\AppData\\Roaming\\mcp\\memory\\memory.json"

[mcp_servers.everything]
command = "npx"
args = ["-y", "@modelcontextprotocol/server-everything"]

[mcp_servers.context7]
command = "npx"
args = ["-y", "@upstash/context7-mcp@latest"]
# 可选：若你有 Context7 API Key，可解除注释并填入，提升速率限制
# [mcp.servers.context7.env]
# CONTEXT7_API_KEY = "YOUR_CONTEXT7_API_KEY"

[mcp_servers.serena]
command = "uvx"
args = ["serena-mcp-server"]
# Serena 为代码语义检索/编辑工具集（需 Python 3.11+；uv 会自动拉取）
# 首次触发其工具可能安装语言服务器，少量耗时属正常

[mcp_servers.figma_remote]
# Figma Remote MCP server (OAuth login required).
url = "https://mcp.figma.com/mcp"
